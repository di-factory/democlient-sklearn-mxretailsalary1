#version = july 14-2023

general_ml:
  seed: 123 #seed for any experiment and model
  encoding: iso-8859-1 #used for open files with specific encodind
  cloud: AWS

paths:
  project_dir: /home/jagpascoe/democlient-sklearn/dif-s-mxretailsalary1 #project directory in this instance
  
  raw_data_dir: ${paths.project_dir}/data/raw #raw_data directory
  processed_data_dir: ${paths.project_dir}/data/processed #processed data, from raw as result of data profiling (notebook)
  interim_data_dir: ${paths.project_dir}/data/interim #intermidiate data, from processed as result of data profiling in pipeline

  reports_dir: ${paths.project_dir}/reports #reports directory from all the project
  models_dir: ${paths.project_dir}/models #where models are saved in different parts of pipeline
  
  api_pycaret_dir: ${paths.project_dir}/API/API_Pycaret #where pycaret saves create_api function (notebook)
  api_fastapi_dir: ${paths.project_dir}/API/API_FastAPI #where API with Fastapi template resides
  api_flask_dir: ${paths.project_dir}/API/API_Flask #where API with Flask template resides


file_names:
  raw_file : raw-data.csv #name of raw_data file
  processed_data: processed_data.csv #name of processed data file
  processed_unseen_data: processed_unseen_data.csv #name of processed UNSEEN data file
  data_file: datafile.csv
  train_features: train_features.csv
  train_labels: train_labels.csv
  validation_features: valid_features.csv
  validation_labels: valid_labels.csv
  test_features: test_features.csv
  test_labels: test_labels.csv
  data_profiling_report: data_profiling_report.html #Name of the report of data profiling (notebook)
  ml_profiling_best: ml_profiling_best
  api_ml_profiling: ml_profiling_best_API


cloud_paths:
  bucket_path: dif-b-democlient-sklearn
  experiment_path: ${cloud_paths.bucket_path}/mxretailsalary1
  mlflow_path: ${cloud_paths.experiment_path}/mlflow
  reports_path: ${cloud_paths.experiment_path}/reports
  rawdata_path: ${cloud_paths.experiment_path}/raw-data
  dvc_path: ${cloud_paths.experiment_path}/dvc-store

data_fields:
  description: About what is the dataset
  features: ['state',
             'income_employee_day',
             'employees_business',
             'salary_employee_day']
  label: salary_employee_day
  
  

data_pipeline:

  drop_features: ['field', 'from','zipcode','undergra','race','race_o']
  keep_features: ['dec_o', 'dec', 'like', 'attr', 'from', 'zipcode', 'prob', 
                  'like_o', 'fun', 'undergra', 'match']
  standarize_text: ['field','from','zipcode','undergra']
  str_to_float: ['income']
  to_categorize: ['field', 'from','zipcode','undergra','race','race_o']
  category_to_num: ['field','from','zipcode','undergra']
  onehot_encoding: ['race','race_o']

  #-----------------------------------------------
  # categorical variables to transform to numerical variables
  numerical_vars_from_numerical: ['income', 'mn_sat', 'tuition']

  # categorical variables to encode
  categorical_vars: ['undergra', 'zipcode']
  categorical_label_extraction: ['zipcode']
  
  # specify the ml algo
  pipeline01: decisiontree
  #--------------------------------

  data_transform_params:
    percent_valid: 0.20
    percent_test: 0.10

mlflow:
  tracking_uri: http://3.140.194.152:5000
  tracking_experiment_name: mxretailsalary1


  