#version = july 14-2023

general_ml:
  seed: 123 #seed for any experiment and model
  encoding: iso-8859-1 #used for open files with specific encodind
  cloud: AWS

  client: democlient
  project: sklearn
  experiment: mxreatilsalary1

  tracking_on: False


paths:
  project_dir: /home/jagpascoe/democlient-sklearn/dif-s-mxretailsalary1 #project directory in this instance
  di_f_pipeline_log_dir: ${paths.project_dir}/logs 

  raw_data_dir: ${paths.project_dir}/data/raw #raw_data directory
  processed_data_dir: ${paths.project_dir}/data/processed #processed data, from raw as result of data profiling (notebook)
  interim_data_dir: ${paths.project_dir}/data/interim #intermidiate data, from processed as result of data profiling in pipeline

  reports_dir: ${paths.project_dir}/reports #reports directory from all the project
  graphs_dir: ${paths.project_dir}/reports/figures #reports directory from all the project
  models_dir: ${paths.project_dir}/models #where models are saved in different parts of pipeline
  
  api_pycaret_dir: ${paths.project_dir}/APIs/API_Pycaret #where pycaret saves create_api function (notebook)
  api_fastapi_dir: ${paths.project_dir}/APIs/FastAPI #where API with Fastapi template resides
  api_flask_dir: ${paths.project_dir}/APIs/API_Flask #where API with Flask template resides

  streamlit_app_dir: ${paths.project_dir}/Apps/Streamlit
  flask_app_dir: ${paths.project_dir}/Apps/Flask

file_names:
  di_f_pipeline_log: ${general_ml.experiment}_log.log
  raw_file : raw-data.csv #name of raw_data file

  processed_data: processed_data.csv #name of processed data file (Notebook)
  processed_unseen_data: processed_unseen_data.csv #name of processed UNSEEN data file (notebook)
  
  data_file: datafile.csv
  train_features: train_features.csv #used for trainning
  train_labels: train_labels.csv
  validation_features: valid_features.csv #used in trainning, mainly in deep learning, otherwise must be concatenated with trainning
  validation_labels: valid_labels.csv
  test_features: test_features.csv #used to test trainning, at the end of each trainning function, as unseen data
  test_labels: test_labels.csv
  
  data_profiling_report: data_profiling_report.html #Name of the report of data profiling (notebook)
  
  ml_profiling_best: ml_profiling_best
  api_ml_profiling: ml_profiling_best_API
  datapipeline: datapipeline
  model: model

  streamlit_predict_model: streamlit_predict.pkl
  fastapi_predict_model: fastapi_predict.pkl
  apiflask_predict_model: apiflask_predict.pkl
  flask_predict_model: flask_predict.pkl
  

cloud_paths:
  bucket_path: dif-b-democlient-sklearn
  experiment_path: ${cloud_paths.bucket_path}/mxretailsalary1
  mlflow_path: ${cloud_paths.experiment_path}/mlflow
  reports_path: ${cloud_paths.experiment_path}/reports
  rawdata_path: ${cloud_paths.experiment_path}/raw-data
  dvc_path: ${cloud_paths.experiment_path}/dvc-store

data_fields:
  description: About what is the dataset

  features:
    - field: state
      type: str
      default: 'Hidalgo'
      aList: [Aguascalientes, BC, BCS, Campeche, Chiapas, Chihuahua, Coahuila, Colima, Durango, Guanajuato, Guerrero, Hidalgo, Jalisco,
      Mexico, CDMX, Michoacan, Morelos, Nayarit, Nuevo Leon, Oaxaca, Puebla, Queretaro, Quintana Roo, SLP, Sinaloa, Sonora, Tabasco, Tamaulipas,
      Tlaxcala, Veracruz, Yucatan, Zacatecas]
    - field: income_employee_day
      type: float
      default: 4000.00
    - field: employees_business
      type: int
      default: 6


  label: 
    salary_employee_day

data_pipeline:
  level: Pycaret
  features_engineering:
    drop_features: []
    keep_features: []
    standarize_text: []
    str_to_float: []
    to_categorize: []
    category_to_num: []
    onehot_encoding: ['state']
  verbose: False

  #-----------------------------------------------
  # categorical variables to transform to numerical variables
  numerical_vars_from_numerical: ['income', 'mn_sat', 'tuition']

  # categorical variables to encode
  categorical_vars: ['undergra', 'zipcode']
  categorical_label_extraction: ['zipcode']
  
  #--------------------------------
  data_transform_params:
    percent_valid: 0.15  # of the 90% resting
    percent_test: 0.10

ml_pipeline:
  modelpipeline: 
    level2: Regression
    level3: Pycaret
    hyperparams:
      epochs: 5
      batch_size: 64
      lr: 0.01
      optimizers: [Adam, ] 
      loss_func : 

  verbose: False


mlflow:
  tracking_uri: http://3.138.151.210:5000
  tracking_experiment_name: mxretailsalary1


  